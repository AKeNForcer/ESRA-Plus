{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c1169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 12:53:44.035694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 12:53:44.619537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-06 12:53:44.619582: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-06 12:53:44.619587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils.explain import ExplainService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53def9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ExplainService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0b4fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bayesian Additive Regression Trees (BART) is a tree-based machine learning method that has been successfully applied to regression and classification problems. The idea is that if you have a bunch of data, and you want to make a prediction about the distribution of the data, you can use a tree to predict the distribution. The problem is that there are a lot of variables in the data that can influence the distribution, so you need a way to predict how the distribution will change over time. In BART, you use a piecewise linear function to estimate the distribution over time, and then you use another piecewise function to calculate the distribution at each node of the tree. This way, you don't have to worry about non-linearity and high-order interactions. In this paper, we introduce an extension of BART, called Model Trees BART (MOTR-BART). In this extension, we use pieceswise linear functions at node levels instead of piecewise constants. This means that instead of using a linear function at every node, we only need to use piecewise functions at the nodes that are correlated with each other. In our approach, local linearities are captured more efficiently and fewer trees are required to achieve equal or better performance than BART.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps.explain(\"What is bart\",\n",
    "\"\"\"\n",
    "Bayesian Additive Regression Trees (BART) is a tree-based machine learning method that has been successfully applied to regression and classification problems. BART assumes regularisation priors on a set of trees that work as weak learners and is very flexible for predicting in the presence of non-linearity and high-order interactions. In this paper, we introduce an extension of BART, called Model Trees BART (MOTR-BART), that considers piecewise linear functions at node levels instead of piecewise constants. In MOTR-BART, rather than having a unique value at node level for the prediction, a linear predictor is estimated considering the covariates that have been used as the split variables in the corresponding tree. In our approach, local linearities are captured more efficiently and fewer trees are required to achieve equal or better performance than BART. Via simulation studies and real data applications, we compare MOTR-BART to its main competitors. R code for MOTR-BART implementation is available at https://github.com/ebprado/MOTR-BART.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5cd7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'order': 1,\n",
       "  'sentence': 'Bayesian Additive Regression Trees (BART) is a tree-based machine learning method that has been successfully applied to regression and classification problems.',\n",
       "  'value': 0.994584},\n",
       " {'order': 2,\n",
       "  'sentence': 'The idea is that if you have a bunch of data, and you want to make a prediction about the distribution of the data, you can use a tree to predict the distribution.',\n",
       "  'value': 1.2002092e-09},\n",
       " {'order': 3,\n",
       "  'sentence': 'The problem is that there are a lot of variables in the data that can influence the distribution, so you need a way to predict how the distribution will change over time.',\n",
       "  'value': 1.1487347e-09},\n",
       " {'order': 4,\n",
       "  'sentence': 'In BART, you use a piecewise linear function to estimate the distribution over time, and then you use another piecewise function to calculate the distribution at each node of the tree.',\n",
       "  'value': 0.0014279856},\n",
       " {'order': 5,\n",
       "  'sentence': \"This way, you don't have to worry about non-linearity and high-order interactions.\",\n",
       "  'value': 1.1767457e-09},\n",
       " {'order': 6,\n",
       "  'sentence': 'In this paper, we introduce an extension of BART, called Model Trees BART (MOTR-BART).',\n",
       "  'value': 0.0035102314},\n",
       " {'order': 7,\n",
       "  'sentence': 'In this extension, we use pieceswise linear functions at node levels instead of piecewise constants.',\n",
       "  'value': 1.0879196e-09},\n",
       " {'order': 8,\n",
       "  'sentence': 'This means that instead of using a linear function at every node, we only need to use piecewise functions at the nodes that are correlated with each other.',\n",
       "  'value': 1.1442518e-09},\n",
       " {'order': 9,\n",
       "  'sentence': 'In our approach, local linearities are captured more efficiently and fewer trees are required to achieve equal or better performance than BART.',\n",
       "  'value': 0.00047781158}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps.highlight(\"What is bart\", \"Bayesian Additive Regression Trees (BART) is a tree-based machine learning method that has been successfully applied to regression and classification problems. The idea is that if you have a bunch of data, and you want to make a prediction about the distribution of the data, you can use a tree to predict the distribution. The problem is that there are a lot of variables in the data that can influence the distribution, so you need a way to predict how the distribution will change over time. In BART, you use a piecewise linear function to estimate the distribution over time, and then you use another piecewise function to calculate the distribution at each node of the tree. This way, you don't have to worry about non-linearity and high-order interactions. In this paper, we introduce an extension of BART, called Model Trees BART (MOTR-BART). In this extension, we use pieceswise linear functions at node levels instead of piecewise constants. This means that instead of using a linear function at every node, we only need to use piecewise functions at the nodes that are correlated with each other. In our approach, local linearities are captured more efficiently and fewer trees are required to achieve equal or better performance than BART.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tsdae]",
   "language": "python",
   "name": "conda-env-.conda-tsdae-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
