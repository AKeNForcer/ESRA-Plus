{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b46dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import math\n",
    "import pdfplumber\n",
    "from nltk.tokenize import word_tokenize\n",
    "from datetime import datetime\n",
    "from utils.gpl_tsdae import GplTsdae\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb52787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-20 19:27:40] INFO [sentence_transformers.SentenceTransformer.__init__:66] Load pretrained SentenceTransformer: ./models/gpl/TSDAE/500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271875ef3dc54544b7fad0e616cc8d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-20 19:27:49] INFO [models.gpl.gpl.toolkit.sbert.load_sbert:68] Set max_seq_length=350\n",
      "[2023-04-20 19:27:49] INFO [beir.retrieval.search.dense.faiss_search._load:39] Loading Faiss ID-mappings from path: ./models/gpl/embedding/TSDAE/my-index.flat.tsv\n",
      "[2023-04-20 19:27:49] INFO [beir.retrieval.search.dense.faiss_search._load:46] Loading Faiss Index from path: ./models/gpl/embedding/TSDAE/my-index.flat.faiss\n"
     ]
    }
   ],
   "source": [
    "gpl = GplTsdae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67ba548b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50688, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (12): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (13): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (14): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (15): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=4096, out_features=50688, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"StabilityAI/stablelm-tuned-alpha-3b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"StabilityAI/stablelm-tuned-alpha-3b\")\n",
    "model.half().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9f92d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        stop_ids = [50278, 50279, 50277, 1, 0]\n",
    "        for stop_id in stop_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "428c90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_paper_and_save_as_txt(paper_id):\n",
    "    if os.path.exists(f\"papers_txt/{paper_id}.txt\"):\n",
    "        return\n",
    "    for try_count in range(6):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(f\"https://export.arxiv.org/pdf/{paper_id}.pdf\", f\"./temp/{paper_id}.pdf\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if try_count >= 5:\n",
    "                raise e\n",
    "            print(f\"{try_count}-retry, get {paper_id} in 10 seconds.\")\n",
    "            sleep(10)\n",
    "    pdfp = pdfplumber.open(f\"./temp/{paper_id}.pdf\")\n",
    "    full_text = '\\n'.join([page.extract_text() for page in pdfp.pages])\n",
    "    tok = sent_tokenize(full_text)\n",
    "    new_tok = []\n",
    "    for s in tok:\n",
    "        score = sum([ c not in \"+-*/=^(){}[]0123456789!@ \" and ord(c) < 128 for c in s ]) / (len(s))\n",
    "        if score >= 0.8:\n",
    "            new_tok.append(s)\n",
    "    with open(f\"papers_txt/{paper_id}.txt\", \"w\") as f:\n",
    "        f.write(' '.join(new_tok))\n",
    "    os.remove(f\"./temp/{paper_id}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4ab09979",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_paper_and_save_as_txt('2010.15778')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07d01d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "papers_txt/1301.3834.txt\n",
      "papers_txt/1301.7521.txt\n",
      "papers_txt/1302.1727.txt\n",
      "papers_txt/1302.3921.txt\n",
      "papers_txt/1302.7145.txt\n",
      "papers_txt/1303.2579.txt\n",
      "papers_txt/1303.2580.txt\n",
      "papers_txt/1303.5751.txt\n",
      "papers_txt/1303.5768.txt\n",
      "papers_txt/1304.1235.txt\n"
     ]
    }
   ],
   "source": [
    "!find papers_txt/13* | tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c40c55b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Is any part of p2p video streaming has same concept as bitcoin?\"\n",
    "paper_id = \"2010.15778\"\n",
    "wc = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3a40217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"papers_txt/{paper_id}.txt\", \"r\") as f:\n",
    "    paper_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e903a1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_ln = word_tokenize(paper_txt)\n",
    "paper_ln = [' '.join(paper_ln[i:i+wc]) for i in range(0, len(paper_ln), wc)]\n",
    "len(paper_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b29a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Review on P2P Video Streaming Sabu M. Thampi Indian Institute of Information Technology and Management – Kerala ( IIITM-K ) , India smthampi @ ieee.org The main objective of this article is to provide an overview of P2P based Video-on-Demand and live streaming services . The article starts with an introduction to media streaming and its simplified architecture . Various solutions offering video streaming in the context of widespread usage of Internet are discussed . This is followed by a short introduction to P2P networks and its applications . A broad discussion on various P2P streaming schemes and P2P'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_ln[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4bdda43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f0d03689fe49beb07147732b25a14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(286, 768)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = gpl.sbert.encode_corpus([ {'title': '', 'text': t} for t in paper_ln ])\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4c070b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8739db8244f34a6aa9066d120fafbfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.2 ms, sys: 188 µs, total: 30.4 ms\n",
      "Wall time: 28.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([26.750092 , 24.725992 , 15.742205 , 17.166065 , 21.121431 ,\n",
       "       18.542736 , 16.108501 , 17.961824 , 20.865734 , 21.299164 ,\n",
       "       22.644932 , 18.591965 , 19.924898 , 21.53347  , 17.528465 ,\n",
       "       20.219898 , 21.407192 , 19.296799 , 21.550507 , 18.321854 ,\n",
       "       21.401644 , 18.272991 , 15.530848 , 19.892708 , 20.796988 ,\n",
       "       20.068285 , 22.38942  , 16.38695  , 19.507298 , 20.65343  ,\n",
       "       15.551199 , 14.809626 , 18.98814  , 13.134424 , 16.463787 ,\n",
       "       15.876736 , 10.6173725, 18.560661 , 18.924587 , 16.15115  ,\n",
       "       18.213997 , 17.67575  , 16.725698 , 15.376694 , 20.536823 ,\n",
       "       18.304985 , 16.364555 , 20.491646 , 19.085903 , 18.00172  ,\n",
       "       17.233421 , 18.313694 , 18.521141 , 19.368706 , 18.797323 ,\n",
       "       14.689584 , 15.176687 , 15.652452 , 18.691277 , 15.748525 ,\n",
       "       14.320398 , 18.210342 , 22.055038 , 20.297798 , 20.58822  ,\n",
       "       18.847082 , 20.09621  , 22.848442 , 21.932081 , 21.023367 ,\n",
       "       13.398948 , 18.844658 , 19.543375 , 16.631697 , 17.505905 ,\n",
       "       18.04152  , 17.089886 , 14.612087 , 26.88788  , 24.06888  ,\n",
       "       19.173168 , 20.334417 , 23.838177 , 18.265942 , 19.656906 ,\n",
       "       21.941729 , 16.471785 , 22.229136 , 15.516641 , 15.991211 ,\n",
       "       20.393614 , 17.210892 , 25.933056 , 27.518055 , 28.35447  ,\n",
       "       31.044847 , 22.918629 , 25.52329  , 27.30653  , 24.814754 ,\n",
       "       27.586315 , 26.662472 , 29.283695 , 15.842849 , 16.52006  ,\n",
       "       16.334026 , 19.554552 , 15.563783 ,  8.236746 , 17.328747 ,\n",
       "       16.85587  , 15.332335 , 14.578797 , 14.828469 , 11.137912 ,\n",
       "       13.327625 , 19.365992 , 16.448408 , 18.460415 , 16.969475 ,\n",
       "       28.85036  , 10.206745 , 24.712452 , 20.983099 , 20.894724 ,\n",
       "       18.159662 , 18.308998 , 18.605091 , 15.335412 , 21.818031 ,\n",
       "       15.709703 , 23.373674 , 20.83693  , 26.4234   , 19.29471  ,\n",
       "       27.06704  , 18.896214 , 17.33883  , 15.825502 , 17.225655 ,\n",
       "       22.98039  , 17.837492 , 14.512232 , 25.800657 , 22.227581 ,\n",
       "       19.489365 , 16.005096 , 23.101017 , 15.721352 , 13.913402 ,\n",
       "       25.132582 , 19.37531  , 20.68215  , 20.779442 , 16.455729 ,\n",
       "       21.20776  , 24.682701 , 28.531015 , 19.242216 , 12.62938  ,\n",
       "       15.9610405, 16.35452  , 12.145445 , 15.621365 , 13.978658 ,\n",
       "       23.529865 , 16.87339  , 12.694504 , 13.6285715, 12.743813 ,\n",
       "       16.416492 , 29.518707 , 27.561079 , 27.05854  , 24.353903 ,\n",
       "       22.696606 , 21.028164 , 25.034603 , 23.22471  , 26.010159 ,\n",
       "       24.831964 , 27.148579 , 28.415003 , 16.69572  , 20.33337  ,\n",
       "       19.131134 , 25.956629 , 19.138023 , 22.771439 , 18.100216 ,\n",
       "       23.021797 , 24.444725 , 25.215832 , 26.501442 , 17.397633 ,\n",
       "       19.964035 , 16.026691 , 18.892624 , 16.856527 , 24.57643  ,\n",
       "       28.628616 , 22.052284 , 22.745287 , 15.5882015, 21.364273 ,\n",
       "       14.106835 , 19.481133 , 22.438948 , 17.120598 , 16.302296 ,\n",
       "       15.644035 , 15.392815 , 24.37461  , 18.119246 , 16.52105  ,\n",
       "       22.416088 , 22.145178 , 18.748577 , 15.391056 , 26.124014 ,\n",
       "       23.153486 , 16.07896  , 14.47195  , 18.835796 , 18.124336 ,\n",
       "       25.176453 , 22.303253 , 25.808172 , 23.938385 , 16.728683 ,\n",
       "       25.931803 , 23.513779 , 26.672344 , 25.917412 , 19.709263 ,\n",
       "       14.712825 , 26.071598 , 17.4357   , 18.479626 , 20.008493 ,\n",
       "       22.743965 , 25.21392  , 15.978944 , 22.911201 , 21.94482  ,\n",
       "       17.212381 , 27.230686 , 20.360538 , 24.09893  , 15.633911 ,\n",
       "       19.284546 , 25.730112 , 25.897236 , 16.303076 , 19.031147 ,\n",
       "       27.581581 , 26.236126 , 27.811874 , 28.78667  , 27.43934  ,\n",
       "       20.562746 , 18.408012 , 19.321    , 12.996063 , 18.765156 ,\n",
       "       16.426699 , 16.30951  , 21.066734 , 16.03883  , 20.257595 ,\n",
       "       22.127182 , 27.087124 , 19.02264  , 22.490124 , 15.842034 ,\n",
       "       21.639027 , 21.213993 , 24.135773 , 27.787275 , 27.393715 ,\n",
       "       22.835146 , 18.447727 , 22.387333 , 25.145206 , 26.990768 ,\n",
       "       10.4892645], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scores = np.sum(np.repeat(gpl.sbert.encode_queries([query]), corpus.shape[0], axis=0) * corpus, axis=1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0a87a547",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 185 µs, sys: 0 ns, total: 185 µs\n",
      "Wall time: 190 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(31.044847,\n",
       "  (95,\n",
       "   ', P2P streaming focuses on the efficient delivery of audio and video content under stiff timing requirements . Stream data are instantaneously received , played , and passed to other associated peers . For example , the P2P file sharing application - BitTorrent permits peers to interchange any segment of the content being distributed since the order in which they arrive is not important . In contrast , such techniques are not viable in streaming applications [ 57 ] . Video files are directly played- out while they are being downloaded . Therefore , pieces , which are received after')),\n",
       " (29.283695,\n",
       "  (102,\n",
       "   'source or a peer . The tree-based systems typically distribute video by actively pushing data from a peer to its children peers [ 62 ] . A common approach to P2P streaming is to organize participating peers into a single tree-structured overlay over which the content is pushed from the source towards all peers e.g . This way organizing peers is called single- tree streaming . In these systems , peers are hierarchically organized in a tree structure where the root is the stream source . The content is spread as a continuous flow of information from the source down')),\n",
       " (28.85036,\n",
       "  (120,\n",
       "   '. When a peer joins the system , it contacts the bootstrapping node to identify a parent in the desired number of trees . In multiple-tree based P2P live streaming systems , the video is encoded into multiple sub-streams , and each sub-stream is delivered over one tree . To keep the population of Page 19 internal nodes balanced among different trees , a new node is added as an internal node to the tree that has the minimum number of internal nodes . To maintain short trees , a new internal node is placed as a child for the')),\n",
       " (29.518707,\n",
       "  (171,\n",
       "   'topology in CliqueStream [ 88 ] The emerging hybrid push-pull P2P streaming overlays present a viable alternative for the traditional way of overlay construction such as tree and mesh since the hybrid design greatly simplifies the overlay construction and maintenance processes and at the same time largely retains its efficiency , and achieves fine-grained control over load . P2P on Demand Video Streaming The existing VoD schemes poses several issues such as infeasibility of multicast , server crashes , and high maintenance and deployment costs of dedicated overlay routers . However , P2P based video streaming provides an alternative architecture'))]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "raw_input = sorted(sorted(list(zip(scores, enumerate(paper_ln))), key=lambda x: -x[0])[:4], key=lambda x: x[1][0])\n",
    "raw_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "72e3fcbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', P2P streaming focuses on the efficient delivery of audio and video content under stiff timing requirements . Stream data are instantaneously received , played , and passed to other associated peers . For example , the P2P file sharing application - BitTorrent permits peers to interchange any segment of the content being distributed since the order in which they arrive is not important . In contrast , such techniques are not viable in streaming applications [ 57 ] . Video files are directly played- out while they are being downloaded . Therefore , pieces , which are received after',\n",
       " 'source or a peer . The tree-based systems typically distribute video by actively pushing data from a peer to its children peers [ 62 ] . A common approach to P2P streaming is to organize participating peers into a single tree-structured overlay over which the content is pushed from the source towards all peers e.g . This way organizing peers is called single- tree streaming . In these systems , peers are hierarchically organized in a tree structure where the root is the stream source . The content is spread as a continuous flow of information from the source down',\n",
       " '. When a peer joins the system , it contacts the bootstrapping node to identify a parent in the desired number of trees . In multiple-tree based P2P live streaming systems , the video is encoded into multiple sub-streams , and each sub-stream is delivered over one tree . To keep the population of Page 19 internal nodes balanced among different trees , a new node is added as an internal node to the tree that has the minimum number of internal nodes . To maintain short trees , a new internal node is placed as a child for the',\n",
       " 'topology in CliqueStream [ 88 ] The emerging hybrid push-pull P2P streaming overlays present a viable alternative for the traditional way of overlay construction such as tree and mesh since the hybrid design greatly simplifies the overlay construction and maintenance processes and at the same time largely retains its efficiency , and achieves fine-grained control over load . P2P on Demand Video Streaming The existing VoD schemes poses several issues such as infeasibility of multicast , server crashes , and high maintenance and deployment costs of dedicated overlay routers . However , P2P based video streaming provides an alternative architecture']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_input = [ t[1][1] for t in raw_input]\n",
    "real_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4a65cb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# StableLM Tuned (Alpha version)\n",
      "- StableLM is a helpful and harmless open-source AI language model developed by StabilityAI.\n",
      "- StableLM is excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n",
      "- StableLM is more than just an information source, StableLM is also able to write poetry, short stories, and make jokes.\n",
      "- StableLM will refuse to participate in anything that could harm a human.\n",
      "Is any part of p2p video streaming has same concept as bitcoin?\n",
      "0), P2P streaming focuses on the efficient delivery of audio and video content under stiff timing requirements. Stream data are instantaneously received, played, and passed to other associated peers. For example, the P2P file sharing application - BitTorrent permits peers to interchange any segment of the content being distributed since the order in which they arrive is not important. In contrast, such techniques are not viable in streaming applications [ 57 ]. Video files are directly played- out while they are being downloaded. Therefore, pieces, which are received after 1) source or a peer. The tree-based systems typically distribute video by actively pushing data from a peer to its children peers [ 62 ]. A common approach to P2P streaming is to organize participating peers into a single tree-structured overlay over which the content is pushed from the source towards all peers e.g. This way organizing peers is called single- tree streaming. In these systems, peers are hierarchically organized in a tree structure where the root is the stream source. The content is spread as a continuous flow of information from the source down 2). When a peer joins the system, it contacts the bootstrapping node to identify a parent in the desired number of trees. In multiple-tree based P2P live streaming systems, the video is encoded into multiple sub-streams, and each sub-stream is delivered over one tree. To keep the population of Page 19 internal nodes balanced among different trees, a new node is added as an internal node to the tree that has the minimum number of internal nodes. To maintain short trees, a new internal node is placed as a child for the 3) topology in CliqueStream [ 88 ] The emerging hybrid push-pull P2P streaming overlays present a viable alternative for the traditional way of overlay construction such as tree and mesh since the hybrid design greatly simplifies the overlay construction and maintenance processes and at the same time largely retains its efficiency, and achieves fine-grained control over load. P2P on Demand Video Streaming The existing VoD schemes poses several issues such as infeasibility of multicast, server crashes, and high maintenance and deployment costs of dedicated overlay routers. However, P2P based video streaming provides an alternative architecture <ans> Yes, some parts of P2P video streaming can be considered similar to Bitcoin in terms of the concept of the decentralized and peer-to-peer file sharing network. Both Bitcoin and P2P file sharing networks utilize peer-to-peer file sharing techniques, where peers exchange their content to other peers, and the content is distributed among the peers in a peer-to-peer manner. However, they differ in their implementation and the underlying principles that govern the data. Bitcoin was created by a group of researchers who were concerned about the security of the network and its decentralized nature. P2P file sharing networks, on the other hand, are decentralized networks where peers exchange their content to other peers, and the content is distributed among the peers in a peer-to-peer manner. The decentralized nature of P2P file sharing networks makes them more resistant to security issues, as the peers can be identified and authenticated without revealing any individual data. Additionally, P2P file sharing networks typically support a large number of peers and a large variety of content types, making them ideal for a wide range of applications such as streaming media, video conferencing, and distributed databases.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "system_prompt = \"\"\"<|SYSTEM|># StableLM Tuned (Alpha version)\n",
    "- StableLM is a helpful and harmless open-source AI language model developed by StabilityAI.\n",
    "- StableLM is excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n",
    "- StableLM is more than just an information source, StableLM is also able to write poetry, short stories, and make jokes.\n",
    "- StableLM will refuse to participate in anything that could harm a human.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"{system_prompt}<|USER|>{query}\\n{' '.join([f'{i}) {t}' for i, t in enumerate(real_input)])} <ans> <|ASSISTANT|>\"\n",
    "# print(prompt)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "tokens = model.generate(\n",
    "  **inputs,\n",
    "  max_new_tokens=256,\n",
    "  temperature=0.7,\n",
    "  do_sample=True,\n",
    "  stopping_criteria=StoppingCriteriaList([StopOnTokens()]),\n",
    "  top_p = 0.95, top_k = 50, early_stopping = False\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "883f8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = tokenizer.decode(tokens[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.split('<ans>')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f59c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tsdae]",
   "language": "python",
   "name": "conda-env-.conda-tsdae-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
